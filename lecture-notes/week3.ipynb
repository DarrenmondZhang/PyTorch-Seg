{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置多层学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.lr_scheduler import LR_Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using poly LR Scheduler!\n"
     ]
    }
   ],
   "source": [
    "net = torchvision.models.resnet34(pretrained=False)\n",
    "\n",
    "LearningRate = 0.002\n",
    "\n",
    "#train_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "# 1x lr for encoder, 10x lr for other\n",
    "enc_params = [p[1] for p in net.named_parameters() if ('resnet' in p[0] or 'encoder' in p[0])]\n",
    "other_params = [p[1] for p in net.named_parameters() if ('resnet' not in p[0] and 'encoder' not in p[0])]\n",
    "train_params = [{'params': enc_params, 'lr': LearningRate},\n",
    "                {'params': other_params, 'lr': LearningRate * 10}]\n",
    "\n",
    "optimizer = torch.optim.SGD(train_params, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = LR_Scheduler('poly', LearningRate, 50, 500)#'poly', 'step', 'cos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>Epoches 0, learning rate param group 1= 0.00200, learning rate param group 2= 0.02000\n",
      "\n",
      "=>Epoches 1, learning rate param group 1= 0.00196, learning rate param group 2= 0.01964\n",
      "\n",
      "=>Epoches 2, learning rate param group 1= 0.00193, learning rate param group 2= 0.01928\n",
      "\n",
      "=>Epoches 3, learning rate param group 1= 0.00189, learning rate param group 2= 0.01892\n",
      "\n",
      "=>Epoches 4, learning rate param group 1= 0.00186, learning rate param group 2= 0.01855\n",
      "\n",
      "=>Epoches 5, learning rate param group 1= 0.00182, learning rate param group 2= 0.01819\n",
      "\n",
      "=>Epoches 6, learning rate param group 1= 0.00178, learning rate param group 2= 0.01783\n",
      "\n",
      "=>Epoches 7, learning rate param group 1= 0.00175, learning rate param group 2= 0.01746\n",
      "\n",
      "=>Epoches 8, learning rate param group 1= 0.00171, learning rate param group 2= 0.01710\n",
      "\n",
      "=>Epoches 9, learning rate param group 1= 0.00167, learning rate param group 2= 0.01673\n",
      "\n",
      "=>Epoches 10, learning rate param group 1= 0.00164, learning rate param group 2= 0.01636\n",
      "\n",
      "=>Epoches 11, learning rate param group 1= 0.00160, learning rate param group 2= 0.01599\n",
      "\n",
      "=>Epoches 12, learning rate param group 1= 0.00156, learning rate param group 2= 0.01562\n",
      "\n",
      "=>Epoches 13, learning rate param group 1= 0.00153, learning rate param group 2= 0.01525\n",
      "\n",
      "=>Epoches 14, learning rate param group 1= 0.00149, learning rate param group 2= 0.01488\n",
      "\n",
      "=>Epoches 15, learning rate param group 1= 0.00145, learning rate param group 2= 0.01451\n",
      "\n",
      "=>Epoches 16, learning rate param group 1= 0.00141, learning rate param group 2= 0.01413\n",
      "\n",
      "=>Epoches 17, learning rate param group 1= 0.00138, learning rate param group 2= 0.01376\n",
      "\n",
      "=>Epoches 18, learning rate param group 1= 0.00134, learning rate param group 2= 0.01338\n",
      "\n",
      "=>Epoches 19, learning rate param group 1= 0.00130, learning rate param group 2= 0.01301\n",
      "\n",
      "=>Epoches 20, learning rate param group 1= 0.00126, learning rate param group 2= 0.01263\n",
      "\n",
      "=>Epoches 21, learning rate param group 1= 0.00122, learning rate param group 2= 0.01225\n",
      "\n",
      "=>Epoches 22, learning rate param group 1= 0.00119, learning rate param group 2= 0.01187\n",
      "\n",
      "=>Epoches 23, learning rate param group 1= 0.00115, learning rate param group 2= 0.01149\n",
      "\n",
      "=>Epoches 24, learning rate param group 1= 0.00111, learning rate param group 2= 0.01110\n",
      "\n",
      "=>Epoches 25, learning rate param group 1= 0.00107, learning rate param group 2= 0.01072\n",
      "\n",
      "=>Epoches 26, learning rate param group 1= 0.00103, learning rate param group 2= 0.01033\n",
      "\n",
      "=>Epoches 27, learning rate param group 1= 0.00099, learning rate param group 2= 0.00994\n",
      "\n",
      "=>Epoches 28, learning rate param group 1= 0.00096, learning rate param group 2= 0.00955\n",
      "\n",
      "=>Epoches 29, learning rate param group 1= 0.00092, learning rate param group 2= 0.00916\n",
      "\n",
      "=>Epoches 30, learning rate param group 1= 0.00088, learning rate param group 2= 0.00877\n",
      "\n",
      "=>Epoches 31, learning rate param group 1= 0.00084, learning rate param group 2= 0.00837\n",
      "\n",
      "=>Epoches 32, learning rate param group 1= 0.00080, learning rate param group 2= 0.00797\n",
      "\n",
      "=>Epoches 33, learning rate param group 1= 0.00076, learning rate param group 2= 0.00757\n",
      "\n",
      "=>Epoches 34, learning rate param group 1= 0.00072, learning rate param group 2= 0.00717\n",
      "\n",
      "=>Epoches 35, learning rate param group 1= 0.00068, learning rate param group 2= 0.00677\n",
      "\n",
      "=>Epoches 36, learning rate param group 1= 0.00064, learning rate param group 2= 0.00636\n",
      "\n",
      "=>Epoches 37, learning rate param group 1= 0.00059, learning rate param group 2= 0.00595\n",
      "\n",
      "=>Epoches 38, learning rate param group 1= 0.00055, learning rate param group 2= 0.00554\n",
      "\n",
      "=>Epoches 39, learning rate param group 1= 0.00051, learning rate param group 2= 0.00512\n",
      "\n",
      "=>Epoches 40, learning rate param group 1= 0.00047, learning rate param group 2= 0.00470\n",
      "\n",
      "=>Epoches 41, learning rate param group 1= 0.00043, learning rate param group 2= 0.00427\n",
      "\n",
      "=>Epoches 42, learning rate param group 1= 0.00038, learning rate param group 2= 0.00384\n",
      "\n",
      "=>Epoches 43, learning rate param group 1= 0.00034, learning rate param group 2= 0.00341\n",
      "\n",
      "=>Epoches 44, learning rate param group 1= 0.00030, learning rate param group 2= 0.00297\n",
      "\n",
      "=>Epoches 45, learning rate param group 1= 0.00025, learning rate param group 2= 0.00252\n",
      "\n",
      "=>Epoches 46, learning rate param group 1= 0.00021, learning rate param group 2= 0.00206\n",
      "\n",
      "=>Epoches 47, learning rate param group 1= 0.00016, learning rate param group 2= 0.00159\n",
      "\n",
      "=>Epoches 48, learning rate param group 1= 0.00011, learning rate param group 2= 0.00110\n",
      "\n",
      "=>Epoches 49, learning rate param group 1= 0.00006, learning rate param group 2= 0.00059\n"
     ]
    }
   ],
   "source": [
    "for i_epoch in range(50):\n",
    "    #train\n",
    "    for i_batch in range(500):\n",
    "        #print('lr: %.4f, epoch: %d'%(scheduler.get_lr()[0], epoch))\n",
    "        scheduler(optimizer, i_batch, i_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小练习：\n",
    "当你分析发现数据集标记的质量很低，你尝试通过降低unet最后一层使训练过程更平滑。你需要稍作修改model/lr_scheduler.py中的LR_Scheduler类达到这一目的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
