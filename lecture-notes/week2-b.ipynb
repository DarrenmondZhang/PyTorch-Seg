{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "from dataset.dataset_unet import prepare_trainset\n",
    "from model.model_unet import UNetResNet34\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image size vs batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "def test_hyperparameters(BATCH_SIZE=16, IMG_SIZE=256, device=device):\n",
    "    train_dl, val_dl = prepare_trainset(BATCH_SIZE=BATCH_SIZE, \n",
    "                                        NUM_WORKERS=8, \n",
    "                                        SEED=2019, \n",
    "                                        IMG_SIZE=IMG_SIZE, debug=True)\n",
    "\n",
    "    for i, (images, masks) in enumerate(train_dl):  # 一次读取一个Bath\n",
    "        images = images.to(device=device, dtype=torch.float)\n",
    "        masks = masks.to(device=device, dtype=torch.float)\n",
    "        if i==0:\n",
    "            break\n",
    "\n",
    "    print(images.size(), masks.size())\n",
    "    \n",
    "    ##\n",
    "    net = UNetResNet34(debug=False)\n",
    "    net = net.to(device=device)\n",
    "    \n",
    "    logit = net(images)\n",
    "    print('Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Count of trainset (for training):  900\nCount of validset (for training):  200\ntorch.Size([8, 1, 256, 256]) torch.Size([8, 1, 256, 256])\nPass\n"
    }
   ],
   "source": [
    "test_hyperparameters(BATCH_SIZE=8, IMG_SIZE=256, device='cuda:0')#'cpu'#'cuda:0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业：自己尝试各种超参数组合\n",
    "- epoch, 10? 200?\n",
    "- early stop round, 1? 20?\n",
    "- learning rate, 10? 0.00001?\n",
    "- batch size\n",
    "- image size, 128, 256, 512, 768, 1024, ...\n",
    "- 使用BCE、Focal Loss、Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习率方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet34(pretrained=False)\n",
    "train_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD(train_params, momentum=0.9, weight_decay=0.0001, lr=0.02)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.3)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 30], gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0200, epoch: 0\n",
      "lr: 0.0196, epoch: 1\n",
      "lr: 0.0194, epoch: 2\n",
      "lr: 0.0192, epoch: 3\n",
      "lr: 0.0190, epoch: 4\n",
      "lr: 0.0188, epoch: 5\n",
      "lr: 0.0186, epoch: 6\n",
      "lr: 0.0185, epoch: 7\n",
      "lr: 0.0183, epoch: 8\n",
      "lr: 0.0181, epoch: 9\n",
      "lr: 0.0179, epoch: 10\n",
      "lr: 0.0177, epoch: 11\n",
      "lr: 0.0176, epoch: 12\n",
      "lr: 0.0174, epoch: 13\n",
      "lr: 0.0172, epoch: 14\n",
      "lr: 0.0170, epoch: 15\n",
      "lr: 0.0169, epoch: 16\n",
      "lr: 0.0167, epoch: 17\n",
      "lr: 0.0165, epoch: 18\n",
      "lr: 0.0164, epoch: 19\n",
      "lr: 0.0162, epoch: 20\n",
      "lr: 0.0160, epoch: 21\n",
      "lr: 0.0159, epoch: 22\n",
      "lr: 0.0157, epoch: 23\n",
      "lr: 0.0156, epoch: 24\n",
      "lr: 0.0154, epoch: 25\n",
      "lr: 0.0152, epoch: 26\n",
      "lr: 0.0151, epoch: 27\n",
      "lr: 0.0149, epoch: 28\n",
      "lr: 0.0148, epoch: 29\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    #train\n",
    "    print('lr: %.4f, epoch: %d'%(scheduler.get_lr()[0], epoch))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  0.5\n",
      "metric:  0.52\n",
      "metric:  0.52\n",
      "metric:  0.52\n",
      "metric:  0.54\n",
      "Epoch    34: reducing learning rate of group 0 to 6.2500e-04.\n",
      "metric:  0.56\n",
      "metric:  0.5800000000000001\n",
      "metric:  0.5800000000000001\n",
      "metric:  0.6000000000000001\n",
      "metric:  0.6000000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "Epoch    44: reducing learning rate of group 0 to 3.1250e-04.\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6200000000000001\n",
      "metric:  0.6400000000000001\n",
      "metric:  0.6400000000000001\n",
      "metric:  0.6600000000000001\n",
      "metric:  0.6600000000000001\n",
      "metric:  0.6800000000000002\n",
      "metric:  0.6800000000000002\n",
      "metric:  0.6800000000000002\n",
      "metric:  0.7000000000000002\n",
      "metric:  0.7000000000000002\n",
      "metric:  0.7000000000000002\n"
     ]
    }
   ],
   "source": [
    "#ReduceLROnPlateau\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                       factor=0.5, patience=4,\n",
    "                                                       verbose=True, threshold=0.0001, \n",
    "                                                       threshold_mode='rel', cooldown=0, \n",
    "                                                       min_lr=0, eps=1e-08)\n",
    "\n",
    "metric = 0.5\n",
    "for epoch in range(30):\n",
    "    #train\n",
    "    #print('lr: %.4f, epoch: %d'%(scheduler.get_lr()[0], epoch))\n",
    "    print('metric: ', metric)\n",
    "    if np.random.rand()<0.2:\n",
    "        metric += 0.02\n",
    "    scheduler.step(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit ('darrenzhang': conda)",
   "language": "python",
   "name": "python36264bitdarrenzhangconda357a0db39b27441d9c70d07f3f243191"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}